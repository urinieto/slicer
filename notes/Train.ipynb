{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import slicer\n",
    "from slicer import models\n",
    "\n",
    "N_MINIBATCH = 64\n",
    "N_EPOCHS = 20\n",
    "LR = 0.01\n",
    "PATIENCE = 3\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"../data/X_train.npy\").reshape((-1, 80, 322, 1))\n",
    "Y_train = np.load(\"../data/Y_train.npy\")\n",
    "W_train = np.load(\"../data/W_train.npy\")\n",
    "\n",
    "X_test = np.load(\"../data/X_test.npy\").reshape((-1, 80, 322, 1))\n",
    "Y_test = np.load(\"../data/Y_test.npy\")\n",
    "W_test = np.load(\"../data/W_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_print = 3\n",
    "for idx in np.where(Y_train == 1)[0][1004:1004 + max_print]:\n",
    "    plt.figure()\n",
    "    plt.imshow(X_train[idx].reshape(80, 322), aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.CNN().model\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LR),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=PATIENCE, restore_best_weights=False)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    batch_size=N_MINIBATCH,\n",
    "    epochs=N_EPOCHS,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=[callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from scipy.ndimage import filters\n",
    "from scipy import signal\n",
    "\n",
    "from slicer import utils\n",
    "from slicer.constants import SR\n",
    "from slicer.constants import HOP_LENGTH\n",
    "from slicer.constants import PEAK_PICKING_THRES\n",
    "from slicer.constants import PINK_NOISE_DUR\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "class Slicer(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def do_the_slice(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def plot(self, nc, bounds, S, offset=0):\n",
    "        # Plot novelty curve\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.plot(nc)\n",
    "        for b in bounds:\n",
    "            plt.vlines(b, ymin=-0.05, ymax=1.05, color='red')\n",
    "\n",
    "        # Plot melspec with boundaries\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        plt.imshow(S, aspect=\"auto\")\n",
    "        for b in bounds:\n",
    "            plt.vlines(b + offset, ymin=0, ymax=80, color='red')\n",
    "        \n",
    "        \n",
    "\n",
    "class Ulrich(Slicer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def do_the_slice(self, mel, plot=False):\n",
    "        # Preprocess\n",
    "        mel = utils.to_db(utils.pad_pink_noise(mel))\n",
    "\n",
    "        # Get patches and do inference\n",
    "        X = utils.get_mel_patches(mel, 1, 322)\n",
    "        Y = model.predict(X.reshape((-1, 80, 322, 1)))\n",
    "\n",
    "        # Obtain boundaries\n",
    "        bounds = utils.peak_picking(Y.flatten(), 0.68)\n",
    "\n",
    "        # Plot results\n",
    "        if plot:\n",
    "            offset = int(PINK_NOISE_DUR * SR // HOP_LENGTH)\n",
    "            self.plot(Y, bounds, mel, offset)\n",
    "\n",
    "        return bounds\n",
    "    \n",
    "\n",
    "class Foote(Slicer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def median_filter(self, X, M=8):\n",
    "        \"\"\"Median filter along the first axis of the feature matrix X.\"\"\"\n",
    "        for i in range(X.shape[1]):\n",
    "            X[:, i] = filters.median_filter(X[:, i], size=M)\n",
    "        return X\n",
    "            \n",
    "    def compute_ssm(self, X, metric=\"seuclidean\"):\n",
    "        \"\"\"Computes the self-similarity matrix of X.\"\"\"\n",
    "        D = distance.pdist(X, metric=metric)\n",
    "        D = distance.squareform(D)\n",
    "        D /= D.max()\n",
    "        return (1 - D) ** 2\n",
    "    \n",
    "    def compute_gaussian_krnl(self, M):\n",
    "        \"\"\"Creates a gaussian kernel following Foote's paper.\"\"\"\n",
    "        g = signal.gaussian(M, M // 3., sym=True)\n",
    "        G = np.dot(g.reshape(-1, 1), g.reshape(1, -1))\n",
    "        G[M // 2:, :M // 2] = -G[M // 2:, :M // 2]\n",
    "        G[:M // 2, M // 2:] = -G[:M // 2, M // 2:]\n",
    "        return G\n",
    "    \n",
    "    def compute_nc(self, X, G):\n",
    "        \"\"\"Computes the novelty curve from the self-similarity matrix X and\n",
    "        the gaussian kernel G.\"\"\"\n",
    "        N = X.shape[0]\n",
    "        M = G.shape[0]\n",
    "        nc = np.zeros(N)\n",
    "\n",
    "        for i in range(M // 2, N - M // 2 + 1):\n",
    "            nc[i] = np.sum(X[i - M // 2:i + M // 2, i - M // 2:i + M // 2] * G)\n",
    "\n",
    "        # Normalize\n",
    "        nc += nc.min()\n",
    "        nc /= nc.max()\n",
    "        return nc\n",
    "    \n",
    "    def do_the_slice(self, mel, plot=False):\n",
    "        \"\"\"Main Foote function.\"\"\"\n",
    "        mel = mel.T\n",
    "        meldb = utils.to_db(mel)\n",
    "        meldb = self.median_filter(meldb, M=64)\n",
    "        D = self.compute_ssm(meldb)\n",
    "        G = self.compute_gaussian_krnl(256)\n",
    "        nc = self.compute_nc(D, G)\n",
    "        bounds = utils.peak_picking(nc.flatten(), 0.15)\n",
    "        \n",
    "        if plot:\n",
    "            plt.figure()\n",
    "            plt.imshow(D)\n",
    "            plt.figure()\n",
    "            plt.imshow(G)\n",
    "            self.plot(nc, bounds, meldb.T)\n",
    "        \n",
    "        return bounds\n",
    "            \n",
    "\n",
    "AUDIO = \"../trains.mp3\"\n",
    "# AUDIO = \"../paranoid.mp3\"\n",
    "# AUDIO = \"../bohemian.mp3\"\n",
    "bounds = Foote().do_the_slice(mel, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, _ = librosa.load(AUDIO, sr=slicer.constants.SR)\n",
    "mel = utils.compute_melspec(audio)\n",
    "bounds = Ulrich().do_the_slice(mel, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "c = librosa.clicks(frames=bounds, sr=SR, hop_length=HOP_LENGTH, length=len(audio))\n",
    "IPython.display.Audio(audio + c, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slicer import evaluate\n",
    "\n",
    "u_slicer = Foote()\n",
    "df = evaluate.eval_slicer(u_slicer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"../models/cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
